{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "import chardet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:30.864317Z",
     "start_time": "2023-06-17T14:31:30.157365Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/17 11:31:32 WARN Utils: Your hostname, mr.local resolves to a loopback address: 127.0.0.1; using 192.168.15.9 instead (on interface en0)\n",
      "23/06/17 11:31:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/17 11:31:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:34.437857Z",
     "start_time": "2023-06-17T14:31:30.869192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "APACHE_SPAM_ASSASSIN = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "DATA_FOLDER = '../data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:34.442518Z",
     "start_time": "2023-06-17T14:31:34.440300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def pull_data():\n",
    "    response = requests.get(APACHE_SPAM_ASSASSIN)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    file_paths = [link.get('href') for link in soup.find_all('a')]\n",
    "    file_paths = [path for path in file_paths if path.split('.')[-1] == 'bz2']\n",
    "\n",
    "    available_data = set(os.listdir(DATA_FOLDER))\n",
    "    file_paths = [path for path in file_paths if path not in available_data and path != 'corpus.parquet']\n",
    "\n",
    "    if len(file_paths) == 0:\n",
    "        print('No data to pull')\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(f'Pulling {file_path}')\n",
    "        response = requests.get(f\"{APACHE_SPAM_ASSASSIN}/{file_path}\")\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_object = io.BytesIO(response.content)\n",
    "        tar = tarfile.open(fileobj=file_object, mode=\"r:bz2\")\n",
    "\n",
    "        extract_dir = Path(DATA_FOLDER)\n",
    "        extract_path = extract_dir.joinpath(Path(file_path))\n",
    "\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "        tar.extractall(extract_path)\n",
    "\n",
    "        tar.close()\n",
    "\n",
    "    size = get_directory_size(\"../data\")\n",
    "    print(f\"Data directory size: {size} bytes\")\n",
    "\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total += os.path.getsize(fp)\n",
    "\n",
    "    return total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:34.450968Z",
     "start_time": "2023-06-17T14:31:34.448786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to pull\n",
      "Data directory size: 121604826 bytes\n"
     ]
    }
   ],
   "source": [
    "pull_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T00:57:47.341226Z",
     "start_time": "2023-06-15T00:57:46.943876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def parse_data():\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    corpus_df = pd.DataFrame(columns=['date', 'difficulty', 'class', 'collection', 'body'])\n",
    "    for dirpath, dirnames, filenames in os.walk(DATA_FOLDER):\n",
    "        print(dirpath)\n",
    "        for filename in filenames:\n",
    "            corpus_path = os.path.join(dirpath, filename)\n",
    "            corpus_df, successful_files, failed_files = incorporate(df, corpus_path, dirpath, successful_files,\n",
    "                                                                    failed_files)\n",
    "    return corpus_df, successful_files, failed_files\n",
    "\n",
    "\n",
    "def incorporate(df, corpus_path, dirpath, successful_files, failed_files):\n",
    "    rawdata = open(corpus_path, 'rb').read()\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "\n",
    "    with open(corpus_path, 'r', encoding=encoding) as f:\n",
    "        [(date, *ids)] = re.findall(r'([\\d]{8})_([a-z]*)_?([a-z]*)_?([\\d]*)\\.tar\\.bz2.*',\n",
    "                                    dirpath)\n",
    "        [difficulty, cls, collection] = parse_ids(ids)\n",
    "        try:\n",
    "            body = f.read()\n",
    "            row = pd.DataFrame({'date': date,\n",
    "                                'difficulty': difficulty,\n",
    "                                'class': cls,\n",
    "                                'collection': collection,\n",
    "                                'body': body}, index=[0, 1, 2, 3, 4])\n",
    "            df = pd.concat([df, row], ignore_index=True)\n",
    "            successful_files.append(corpus_path)\n",
    "        except Exception as E:\n",
    "            print(E)\n",
    "            failed_files.append(corpus_path)\n",
    "    return df, successful_files, failed_files\n",
    "\n",
    "\n",
    "def parse_ids(ids):\n",
    "    cls, difficulty, collection = None, None, None\n",
    "    match ids:\n",
    "        case [cls, '', '']:\n",
    "            difficulty = None\n",
    "            collection = None\n",
    "        case [difficulty, cls, '']:\n",
    "            collection = None\n",
    "        case [difficulty, cls, collection]:\n",
    "            pass\n",
    "        case _:\n",
    "            pass\n",
    "\n",
    "    return [difficulty, cls, collection]\n",
    "\n",
    "\n",
    "def save_as_parquet(df):\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.parquet(f'{DATA_FOLDER}/corpus.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:34.465659Z",
     "start_time": "2023-06-17T14:31:34.460796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if 'corpus.parquet' in set(os.listdir(DATA_FOLDER)):\n",
    "    df = spark.read.parquet(f'{DATA_FOLDER}/corpus.parquet')\n",
    "    corpus_df = df.toPandas()\n",
    "else:\n",
    "    corpus_df, successful_files, failed_files = parse_data()\n",
    "    save_as_parquet(corpus_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:40.455602Z",
     "start_time": "2023-06-17T14:31:34.465893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "           date difficulty class collection  \\\n0      20030228       hard   ham       None   \n1      20030228       hard   ham       None   \n2      20030228       hard   ham       None   \n3      20030228       hard   ham       None   \n4      20030228       hard   ham       None   \n...         ...        ...   ...        ...   \n53650  20030228       easy   ham       None   \n53651  20030228       easy   ham       None   \n53652  20030228       easy   ham       None   \n53653  20030228       easy   ham       None   \n53654  20030228       easy   ham       None   \n\n                                                    body  \n0      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n1      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n2      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n3      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n4      Return-Path: <bounce-lghtml-2534368@sprocket.l...  \n...                                                  ...  \n53650  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53651  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53652  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53653  From exmh-workers-admin@redhat.com  Tue Aug 27...  \n53654  From fork-admin@xent.com  Wed Sep 25 10:24:54 ...  \n\n[53655 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>difficulty</th>\n      <th>class</th>\n      <th>collection</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20030228</td>\n      <td>hard</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>Return-Path: &lt;bounce-lghtml-2534368@sprocket.l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53650</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53651</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53652</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53653</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From exmh-workers-admin@redhat.com  Tue Aug 27...</td>\n    </tr>\n    <tr>\n      <th>53654</th>\n      <td>20030228</td>\n      <td>easy</td>\n      <td>ham</td>\n      <td>None</td>\n      <td>From fork-admin@xent.com  Wed Sep 25 10:24:54 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>53655 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:31:40.474107Z",
     "start_time": "2023-06-17T14:31:40.460243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def extract_headers(row):\n",
    "    try:\n",
    "        [headers, body] = row['body'].split('\\n\\n', maxsplit=1)\n",
    "        header_rows = headers.split('\\n')\n",
    "        current_key = None\n",
    "        for h in header_rows:\n",
    "            row, current_key = parse_header(row, h, current_key)\n",
    "        row['body'] = body\n",
    "    except Exception as e:\n",
    "        row['header_error'] = e\n",
    "        row['has_headers'] = False\n",
    "    return row\n",
    "\n",
    "\n",
    "def parse_header(row, h, current_key):\n",
    "    match re.split(r\"([\\w\\-]+)\\:\\s*\", h):\n",
    "        case ['', key, value]:\n",
    "            row[key.lower()] = value\n",
    "            current_key = key.lower()\n",
    "        case [value]:\n",
    "            if current_key:\n",
    "                row[current_key] += value\n",
    "        case _:\n",
    "            pass\n",
    "    return row, current_key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:59:07.528472Z",
     "start_time": "2023-06-17T15:59:07.523979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "preproc_df = corpus_df.drop_duplicates(subset='body')\n",
    "preproc_df.loc[:, 'has_headers'] = True\n",
    "preproc_df = preproc_df.apply(extract_headers, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T17:51:58.583229Z",
     "start_time": "2023-06-17T17:51:03.005869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "reduced_preproc_df = preproc_df.dropna(thresh=1000, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:05:53.809782Z",
     "start_time": "2023-06-17T18:05:53.693097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "def extract_email_address(row, cols):\n",
    "    for col in cols:\n",
    "        if str(row[col]) and type(row[col]) != list:\n",
    "            row[col] = re.findall(r\"([^\\s\\<]+\\@[^\\s\\>]+)\", str(row[col])) or None\n",
    "    return row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:05:54.049374Z",
     "start_time": "2023-06-17T18:05:54.040692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "envelope_cols = ['delivered-to', 'errors-to', 'from', 'in-reply-to', 'list-id', 'message-id', 'received', 'references',\n",
    "                 'reply-to', 'return-path', 'sender', 'to', 'x-beenthere']\n",
    "extracted_emails_df = reduced_preproc_df.apply(lambda r: extract_email_address(r, envelope_cols), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:06:11.094997Z",
     "start_time": "2023-06-17T18:06:09.315968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "matching_cols = [\n",
    "    ['delivered-to', 'to'],\n",
    "    ['errors-to', 'from'],\n",
    "    ['errors-to', 'return-path'],\n",
    "    ['from', 'reply-to'],\n",
    "    ['from', 'return-path'],\n",
    "    ['from', 'sender'],\n",
    "    ['x-beenthere', 'list-id']\n",
    "]\n",
    "\n",
    "def envelope_cols_match(row):\n",
    "    for [col1, col2] in matching_cols:\n",
    "        values_exist = row[col1] and row[col2]\n",
    "        if not values_exist:\n",
    "            return row\n",
    "        row[f'feat-match-{col1}-{col2}'] = 1 if set(row[col1]) == set(row[col2]) else 0\n",
    "    return row"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:06:12.650560Z",
     "start_time": "2023-06-17T18:06:12.643983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "matched_envelopes_df = extracted_emails_df.apply(envelope_cols_match, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:06:32.601989Z",
     "start_time": "2023-06-17T18:06:22.345541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "       feat-match-delivered-to-to  feat-match-errors-to-from  \\\ncount                 7760.000000                4569.000000   \nmean                     0.147938                   0.003502   \nstd                      0.355062                   0.059079   \nmin                      0.000000                   0.000000   \n25%                      0.000000                   0.000000   \n50%                      0.000000                   0.000000   \n75%                      0.000000                   0.000000   \nmax                      1.000000                   1.000000   \n\n       feat-match-errors-to-return-path  feat-match-from-reply-to  \\\ncount                       4568.000000               1662.000000   \nmean                           0.992557                  0.293020   \nstd                            0.085961                  0.455285   \nmin                            0.000000                  0.000000   \n25%                            1.000000                  0.000000   \n50%                            1.000000                  0.000000   \n75%                            1.000000                  1.000000   \nmax                            1.000000                  1.000000   \n\n       feat-match-from-return-path  feat-match-from-sender  \ncount                  1662.000000             1654.000000  \nmean                      0.010229                0.007860  \nstd                       0.100648                0.088333  \nmin                       0.000000                0.000000  \n25%                       0.000000                0.000000  \n50%                       0.000000                0.000000  \n75%                       0.000000                0.000000  \nmax                       1.000000                1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feat-match-delivered-to-to</th>\n      <th>feat-match-errors-to-from</th>\n      <th>feat-match-errors-to-return-path</th>\n      <th>feat-match-from-reply-to</th>\n      <th>feat-match-from-return-path</th>\n      <th>feat-match-from-sender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7760.000000</td>\n      <td>4569.000000</td>\n      <td>4568.000000</td>\n      <td>1662.000000</td>\n      <td>1662.000000</td>\n      <td>1654.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.147938</td>\n      <td>0.003502</td>\n      <td>0.992557</td>\n      <td>0.293020</td>\n      <td>0.010229</td>\n      <td>0.007860</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.355062</td>\n      <td>0.059079</td>\n      <td>0.085961</td>\n      <td>0.455285</td>\n      <td>0.100648</td>\n      <td>0.088333</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols = [col for col in matched_envelopes_df.columns if re.match(r\"^feat\\-.*$\", col) is not None]\n",
    "matched_envelopes_df[feat_cols].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:06:32.631207Z",
     "start_time": "2023-06-17T18:06:32.606039Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "count    6109.000000\nmean        0.478147\nstd         0.499563\nmin         0.000000\n25%         0.000000\n50%         0.000000\n75%         1.000000\nmax         1.000000\nName: feat-duplicate-message-id, dtype: float64"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_ids = {}\n",
    "\n",
    "def duplicate_message_id(row):\n",
    "    if not row['message-id']:\n",
    "        matched_envelopes_df.loc[row.name, 'feat-duplicate-message-id'] = 0\n",
    "        return row\n",
    "\n",
    "    for message_id in row['message-id']:\n",
    "        if message_id not in message_ids:\n",
    "            message_ids[message_id] = row.name\n",
    "            matched_envelopes_df.loc[row.name, 'feat-duplicate-message-id'] = 0\n",
    "        else:\n",
    "            matched_envelopes_df.loc[message_ids[message_id], 'feat-duplicate-message-id'] = 1\n",
    "    return row\n",
    "\n",
    "matched_envelopes_df.apply(duplicate_message_id, axis=1)\n",
    "duplicate_messages_df = matched_envelopes_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T18:13:23.094265Z",
     "start_time": "2023-06-17T18:13:21.877125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_cols = ['cc', 'content-type', 'subject', 'x-mailer']\n",
    "categorical_cols = ['content-transfer-encoding', 'mime-version', 'precedence', 'x-mailman-version', 'x-msmail-priority',\n",
    "                    'ax-priority', 'x-spam-level', 'x-spam-status']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                                      NaN\n1295     No, hits=-32.7 required=5.0\\ttests=ALL_CAP_POR...\n1300     Yes, hits=5.2 required=5.0 tests=SUBJ_HAS_SPAC...\n1330     Yes, hits=11.5 required=5.0 tests=NO_REAL_NAME...\n1350     No, hits=-9.1 required=5.0\\ttests=AWL,FORGED_R...\n                               ...                        \n50542    No, hits=-5.0 required=5.0\\ttests=AWL,EMAIL_AT...\n50552    No, hits=-3.1 required=5.0\\ttests=AWL,X_LOOP,X...\n50557    No, hits=-10.2 required=7.0\\ttests=AWL,EMAIL_A...\n50572    No, hits=-645.4 required=5.0\\ttests=AWL\\tversi...\n50577    No, hits=-14.5 required=5.0\\ttests=AWL,DEAR_SO...\nName: x-spam-status, Length: 1786, dtype: object"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T16:47:08.991680Z",
     "start_time": "2023-06-17T16:47:08.986284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
